{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPBwEjRwtVKWTonyUGPcRhy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LJrDhYw5rJ5u"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","from torch.autograd import Variable\n","\n","def cvt_coord(i):\n","    return [(i/5-2)/2., (i%5-2)/2.]\n","    \n","def get_coord():\n","    np_coord_tensor = np.zeros((64, 25, 2))\n","    for i in range(25):\n","        np_coord_tensor[:,i,:] = np.array(cvt_coord(i))\n","        \n","    return np_coord_tensor\n","\n","class ConvBlock(nn.Module):\n","    def __init(self):\n","        super(ConvBlock, self).__init__()\n","        \n","        self.conv1 = nn.Conv2d(3, 24, 3, stride=2, padding=1)\n","        self.batch_norm1 = nn.BatchNorm2d(24)\n","        self.conv2 = nn.Conv2d(24, 24, 3, stride=2, padding=1)\n","        self.batch_norm2 = nn.BatchNorm2d(24)\n","        self.conv3 = nn.Conv2d(24, 24, 3, stride=2, padding=1)\n","        self.batch_norm3 = nn.BatchNorm2d(24)\n","        self.conv4 = nn.Conv2d(24, 24, 3, stride=2, padding=1)\n","        self.batch_norm4 = nn.BatchNorm2d(24)\n","        \n","    def forward(self, img):\n","        x = self.conv1(img)\n","        x = F.relu(x)\n","        x = self.batch_norm1(x)\n","        \n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = self.batch_norm2(x)\n","        \n","        x = self.conv3(x)\n","        x = F.relu(x)\n","        x = self.batch_norm3(x)\n","        \n","        x = self.conv4(x)\n","        x = F.relu(x)\n","        x = self.batch_norm4(x)\n","        \n","        return x\n","        \n","class FCBlock(nn.Module):\n","    def __init__(self):\n","        super(FCBlock, self).__init__()\n","        self.fc2 = nn.Linear(256, 256)\n","        self.fc3 = nn.Linear(256, 10)\n","        \n","    def forward(self, x):\n","        x = self.fc2(x)\n","        x = F.relu(x)\n","        x = F.dropout(x)\n","        x = self.fc3(x)\n","        \n","        return x\n","        \n","class RN(nn.Module):\n","    def __init__(self, batch_size=64):\n","        super(RN, self).__init__()\n","        self.name = 'RN'\n","        \n","        self.conv = ConvBlock()\n","        \n","        self.g_fc1 = nn.Linear((24+2)*2+11, 256)\n","        self.g_fc2 = nn.Linear(256, 256)\n","        self.g_fc3 = nn.Linear(256, 256)\n","        self.g_fc4 = nn.Linear(256, 256)\n","        \n","        self.f_fc1 = nn.Linear(256, 256)\n","        self.coord_oi = Variable(torch.FloatTensor(batch_size, 2).cuda())\n","        self.coord_oj = Variable(torch.FloatTensor(batch_size, 2).cuda())\n","        \n","        self.coord_tensor = Variable(torch.FloatTensor(64, 25, 2).cuda())\n","        self.coord_tensor.data.copy_(torch.from_numpy(get_coord()))\n","        \n","        self.fcout = FCBlock()\n","        \n","        self.optimizer = optim.Adam(self.parameters(), lr=0.0001)\n","        \n","    def forward(self, img, ques):\n","        x = self.conv(img)\n","        # 64(batch) * 24 * 5 * 5\n","        mb = x.size()[0] # 64\n","        n_channels = x.size()[1] # 24\n","        d = x.size()[2] # 5\n","        x_flat = x.view(mb, n_channels, d*d).permute(0,2,1)\n","        # x.view(mb, n_channels, d*d) -> (64, 24, 25)\n","        # after permute -> (64, 25, 24)\n","        x_flat = torch.cat([x_flat, self.coord_tensor], 2)\n","        \n","        ques = torch.unsqueeze(ques, 1)\n","        ques = ques.repeat(1, 25, 1)\n","        ques = torch.unsqueeze(ques, 2)\n","        \n","        x_i = torch.unsqueeze(x_flat, 1)\n","        x_i = x_i.repeat(1, 25, 1, 1)\n","        x_j = torch.unsqueeze(x_flat, 2)\n","        x_j = torch.cat([x_j, ques], 3)\n","        x_j = x_j.repeat(1, 1, 25, 1)\n","        \n","        x_full = torch.cat([x_i, x_j], 3)\n","        \n","        x_ = x_full.view(mb * (d*d) * (d*d), 70)\n","        \n","        x_ = self.g_fc1(x_)\n","        x_ = F.relu(x_)\n","        x_ = self.g_fc2(x_)\n","        x_ = F.relu(x_)\n","        x_ = self.g_fc3(x_)\n","        x_ = F.relu(x_)\n","        x_ = self.g_fc4(x_)\n","        x_ = F.relu(x_)\n","        \n","        x_g = x_.view(mb, (d*d) * (d*d), 256)\n","        x_g = x_g.sum(1).squeeze()\n","        \n","        x_f = self.f_fc1(x_g)\n","        x_f = F.relu(x_g)\n","        \n","        return self.fcout(x_f)\n","        \n","    def train_(self, img, ques, label):\n","        self.optimizer.zero_grad()\n","        output = self(img, ques)\n","        loss = F.cross_entropy(output, label)\n","        pred = output.data.max(1)[1]\n","        correct = preq.qe(label.data).cpu().sum()\n","        accuracy = correct * 100. / len(label)\n","        return accuracy, loss\n","        \n","    def test_(self, img, ques, label):\n","        output = self(img, ques)\n","        loss = F.cross_entropy(output, label)\n","        pred = output.data.max(1)[1]\n","        correct = preq.qe(label.data).cpu().sum()\n","        accuracy = correct * 100. / len(label)\n","        return accuracy, loss\n","        \n","    def save_model():\n","        torch.save(self.state_dict(), f\"{self.name}_{epoch}.pth\")"]}]}